{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- How to handle NaN in encoder? (drop before classification)\n",
    "- Mess with classifier parameters\n",
    "- test classifier\n",
    "- how to handle repeats?\n",
    "- change order of operations so that slave_indexes match unclassified_data...how to do this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import exploringShipLogbooks.wordCount as wc\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import collections\n",
    "\n",
    "from exploringShipLogbooks.basic_utils import isolate_training_data\n",
    "from exploringShipLogbooks.basic_utils import extract_logbook_data\n",
    "from exploringShipLogbooks.basic_utils import isolate_columns\n",
    "from exploringShipLogbooks.basic_utils import encode_data_df\n",
    "from exploringShipLogbooks.basic_utils import clean_data\n",
    "\n",
    "from exploringShipLogbooks.config import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load and clean data\n",
    "### Load CLIWOC ship logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2825: DtypeWarning: Columns (5,6,7,8,11,13,18,19,23,24,25,26,28,29,30,34,35,38,43,44,46,73,77,81,82,84,85,87,88,94,96,97,98,99,111,114,116,119,120,122,124,125,127,129,131,133,135,137,140) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "# extract data from zip file\n",
    "cliwoc_data = extract_logbook_data('CLIWOC15.csv')\n",
    "#cliwoc_data = cliwoc_data.loc[50000:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find definite slave data in CLIWOC data set\n",
    "- These logs will be used to test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  464  logs that mention slaves\n"
     ]
    }
   ],
   "source": [
    "# extract logs that mention slaves\n",
    "mentions_slaves = wc.count_key_words(cliwoc_data, text_columns, slave_words)\n",
    "slave_index = mentions_slaves[(mentions_slaves['ContainsKeyWord'] != 0)].index\n",
    "slave_mask = (mentions_slaves['ContainsKeyWord'] != 0)\n",
    "\n",
    "print('Found ', len(slave_index), ' logs that mention slaves')\n",
    "\n",
    "# cleanup\n",
    "del mentions_slaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean CLIWOC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove undesired columns\n",
    "cliwoc_data = isolate_columns(cliwoc_data, desired_columns)\n",
    "\n",
    "# clean data (make all same case)\n",
    "#cliwoc_data = clean_data(cliwoc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Slave Voyages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = './exploringShipLogbooks/data/tastdb-exp-2010'\n",
    "slave_voyage_logs = df = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Slave voyages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slave_voyage_desired_cols = ['portdep', 'portret', 'shipname', \n",
    "                             'rig', 'national', 'yeardep']\n",
    "slave_voyage_logs = isolate_columns(slave_voyage_logs, slave_voyage_desired_cols)\n",
    "\n",
    "slave_voyage_logs.columns = ['ShipName', 'Nationality', 'ShipType', \n",
    "                             'VoyageFrom', 'VoyageTo', 'Year']\n",
    "\n",
    "#slave_voyage_logs = clean_data(slave_voyage_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding two indices to keep track of what dataset is which. We need to use this to index the classifier data later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_data_indices_no_slaves = pd.DataFrame(0, index=cliwoc_data[~slave_mask].index, columns = ['data_indices'])\n",
    "cliwoc_data_indices_slaves = pd.DataFrame(1, index=cliwoc_data[slave_mask].index, columns = ['data_indices'])\n",
    "slave_data_indices = pd.DataFrame(2, index=(slave_voyage_logs.index + cliwoc_data_indices.tail(1).index[0]), columns = ['data_indices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = pd.concat([cliwoc_data_indices, slave_data_indices], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- okay, now back to your code. commented out the last lines since the above cells take care of indexing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([cliwoc_data, slave_voyage_logs], ignore_index = True)\n",
    "all_data = clean_data(all_data)\n",
    "\n",
    "# keep track of slave training data indices\n",
    "#last_cliwoc_index = len(cliwoc_data)\n",
    "#new_last_index = len(slave_voyage_logs) + last_cliwoc_index\n",
    "#training_slave_indices = list(range(last_cliwoc_index, new_last_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## further cleaning of data\n",
    "\n",
    "- Nationality: \n",
    "    - british and great britain\n",
    "    - french and france\n",
    "    - spanish and spain\n",
    "    - usa and american\n",
    "    \n",
    "- ShipName:\n",
    "    - 9740 unique shipnames good column to filter!\n",
    "    \n",
    "- ShipType:\n",
    "    - 118743 nan values for ship types (remove these columns?)\n",
    "    - duplicate types in different languages, will this be a problem?\n",
    "    \n",
    "- VoyageFrom:\n",
    "    - 1129 unique voyage starting points\n",
    "    \n",
    "- VoyageTo:\n",
    "    - 1074 unique voyage ending points\n",
    "    \n",
    "- Year:\n",
    "    - filter out the ships from the slave dataset that are before 1600?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- finds the rows where ShipType is equal to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ship_type_ind = ~(all_data['ShipType'] == 'nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- finds the empty strings in the ShipName column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empty_rows_ind = ~all_data['ShipName'].isin(all_data['ShipName'].value_counts().keys()[all_data['ShipName'].value_counts().keys() == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- finds the ShipNames greater than some value count. Used 0 so the non-slave ship training data would be available..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ship_name_ind = all_data['ShipName'].isin(all_data['ShipName'].value_counts().keys()[all_data['ShipName'].value_counts()>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = all_data[(empty_rows_ind & ship_name_ind & ship_type_ind)]\n",
    "indices = indices[(empty_rows_ind & ship_name_ind & ship_type_ind)]\n",
    "indices.index = range(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data[ship_name_ind]\n",
    "indices = indices[ship_name_ind]\n",
    "indices.index = range(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio('dog','dog butt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(bob):\n",
    "    print(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "5      True\n",
       "6      True\n",
       "7      True\n",
       "8      True\n",
       "9      True\n",
       "10     True\n",
       "11     True\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15     True\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27     True\n",
       "28     True\n",
       "29     True\n",
       "       ... \n",
       "970    True\n",
       "971    True\n",
       "972    True\n",
       "973    True\n",
       "974    True\n",
       "975    True\n",
       "976    True\n",
       "977    True\n",
       "978    True\n",
       "979    True\n",
       "980    True\n",
       "981    True\n",
       "982    True\n",
       "983    True\n",
       "984    True\n",
       "985    True\n",
       "986    True\n",
       "987    True\n",
       "988    True\n",
       "989    True\n",
       "990    True\n",
       "991    True\n",
       "992    True\n",
       "993    True\n",
       "994    True\n",
       "995    True\n",
       "996    True\n",
       "997    True\n",
       "998    True\n",
       "999    True\n",
       "Name: Nationality, dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['Nationality'][0:1000].apply(lambda row: fuzz.partial_ratio(all_data['Nationality'][0:1000], row) >= 85)#, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fuzzy_wuzzy_rows(name):\n",
    "    matches = df.apply(lambda row: (fuzz.partial_ratio(row['Nationality'], name) >= 85), axis=1)\n",
    "    return [i for i, x in enumerate(matches) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame( {'id':[1, 2, 3, 4, 5, 6], 'name':['dog', 'cat', 'mad cat', 'good dog', 'bad dog', 'chicken']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mad cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>good dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bad dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name\n",
       "0   1       dog\n",
       "1   2       cat\n",
       "2   3   mad cat\n",
       "3   4  good dog\n",
       "4   5   bad dog\n",
       "5   6   chicken"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(name):\n",
    "    matches = df.apply(lambda row: (fuzz.partial_ratio(row['Nationality'], name) >= 85), axis=1)\n",
    "    return [i for i, x in enumerate(matches) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         []\n",
       "1         []\n",
       "2         []\n",
       "3         []\n",
       "4         []\n",
       "5         []\n",
       "6         []\n",
       "7         []\n",
       "8         []\n",
       "9         []\n",
       "10        []\n",
       "11        []\n",
       "12        []\n",
       "13        []\n",
       "14        []\n",
       "15        []\n",
       "16        []\n",
       "17        []\n",
       "18        []\n",
       "19        []\n",
       "20        []\n",
       "21        []\n",
       "22        []\n",
       "23        []\n",
       "24        []\n",
       "25        []\n",
       "26        []\n",
       "27        []\n",
       "28        []\n",
       "29        []\n",
       "          ..\n",
       "315198    []\n",
       "315199    []\n",
       "315200    []\n",
       "315201    []\n",
       "315202    []\n",
       "315203    []\n",
       "315204    []\n",
       "315205    []\n",
       "315206    []\n",
       "315207    []\n",
       "315208    []\n",
       "315209    []\n",
       "315210    []\n",
       "315211    []\n",
       "315212    []\n",
       "315213    []\n",
       "315214    []\n",
       "315215    []\n",
       "315216    []\n",
       "315217    []\n",
       "315218    []\n",
       "315219    []\n",
       "315220    []\n",
       "315221    []\n",
       "315222    []\n",
       "315223    []\n",
       "315224    []\n",
       "315225    []\n",
       "315226    []\n",
       "315227    []\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.apply(lambda row: func(row['Nationality']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "- Must encode data before separating, otherwise values that do not occur in a subset will be encoded differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = encode_data_df(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract training data, and create list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# slave_logs training data is from slave voyages data set\n",
    "training_slave_indices = (indices['data_indices'] == 1)\n",
    "slave_logs = all_data[training_slave_indices]\n",
    "\n",
    "criteria = {'ShipName': non_slave_ships}\n",
    "no_slave_logs, no_slave_mask = isloate_training_data(cliwoc_data, criteria)\n",
    "\n",
    "# remaining data is unclassified \n",
    "unclassified_logs = all_data.drop(all_data.index[training_slave_indices])\n",
    "\n",
    "# convert to numpy array\n",
    "unclassified_logs = unclassified_logs.as_matrix()\n",
    "\n",
    "# clean-up\n",
    "#del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_slave_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create list of classes for training data (0 is for non-slave, 1 is for slave)\n",
    "# index matches training_data\n",
    "classes = np.zeros(len(no_slave_logs))\n",
    "classes = np.append(classes, np.ones(len(slave_logs)))\n",
    "\n",
    "# joint training data\n",
    "training_data = pd.concat([no_slave_logs, slave_logs], ignore_index = True)\n",
    "\n",
    "# convert to numpy array\n",
    "training_data = training_data.as_matrix()\n",
    "\n",
    "# cleanup\n",
    "del no_slave_logs, slave_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fit training data to classifier\n",
    "- **note!** first column of numpy array is index! do not include in classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "classifier.fit(training_data, classes)\n",
    "\n",
    "predictions = classifier.predict(unclassified_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_count = collections.Counter(predictions)\n",
    "print(predictions_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classifier\n",
    "- check if slave logs from cliwoc data were classified correctly (want mostly classified as 1)\n",
    "- compare first column with slave_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
