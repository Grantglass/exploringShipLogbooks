{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# super questionable code for reviewing data. make sure to leave ship name in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ind = -50\n",
    "end_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VoyageFrom</th>\n",
       "      <th>VoyageTo</th>\n",
       "      <th>ShipName</th>\n",
       "      <th>ShipType</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Year</th>\n",
       "      <th>slave_logs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogbookIdent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Helvoetsluis</td>\n",
       "      <td>Curacao</td>\n",
       "      <td>kenau hasselaar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Porte Praijo</td>\n",
       "      <td>Schapeneiland</td>\n",
       "      <td>havick</td>\n",
       "      <td>Sloep</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Batavia</td>\n",
       "      <td>Europa</td>\n",
       "      <td>havick</td>\n",
       "      <td>Korvet</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Frankrijk</td>\n",
       "      <td>Nederlands IndiÃ«</td>\n",
       "      <td>nymphe</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>French</td>\n",
       "      <td>1811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Batavia</td>\n",
       "      <td>Nieuwediep</td>\n",
       "      <td>jan en cornelis</td>\n",
       "      <td>Koopvaarder</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>Nieuwediep</td>\n",
       "      <td>boreas</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1773</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>St Eustacius</td>\n",
       "      <td>Texel</td>\n",
       "      <td>jason</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Texel</td>\n",
       "      <td>Fonciaal</td>\n",
       "      <td>nassau-weilburgh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Lissabon</td>\n",
       "      <td>Mesurado</td>\n",
       "      <td>thetis</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Texel</td>\n",
       "      <td>West-Indie</td>\n",
       "      <td>haarlemmerhout</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Texel</td>\n",
       "      <td>West-Indie</td>\n",
       "      <td>haarlemmerhout</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Vlissingen</td>\n",
       "      <td>Suriname</td>\n",
       "      <td>st maartensdijk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>St Eustatius</td>\n",
       "      <td>Texel</td>\n",
       "      <td>amazone</td>\n",
       "      <td>Fregat</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Vlissingen</td>\n",
       "      <td>Tafelbaai</td>\n",
       "      <td>prins frederik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Simonsbaai</td>\n",
       "      <td>Mountsbaai</td>\n",
       "      <td>prins frederik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>1819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Madras</td>\n",
       "      <td>Batavia</td>\n",
       "      <td>colchester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Madras</td>\n",
       "      <td>alfred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Java Head</td>\n",
       "      <td>St Helena</td>\n",
       "      <td>alfred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Simons Bay</td>\n",
       "      <td>Madras</td>\n",
       "      <td>alfred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Simons Bay</td>\n",
       "      <td>Downs UK via St Helena</td>\n",
       "      <td>northumberland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>St Helena</td>\n",
       "      <td>Canton</td>\n",
       "      <td>northumberland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Bombay</td>\n",
       "      <td>Canton</td>\n",
       "      <td>northumberland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Dungeness</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>northumberland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Java</td>\n",
       "      <td>royal charlotte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Benkulen, Sumatra</td>\n",
       "      <td>royal charlotte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Madras</td>\n",
       "      <td>royal charlotte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Plymouth</td>\n",
       "      <td>Calcutta</td>\n",
       "      <td>georgina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Motherbank</td>\n",
       "      <td>St Helena</td>\n",
       "      <td>georgina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Table Bay</td>\n",
       "      <td>London</td>\n",
       "      <td>georgina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Bali</td>\n",
       "      <td>St Helena</td>\n",
       "      <td>glatton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Sumbava (E Bali)</td>\n",
       "      <td>glatton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Fort St David</td>\n",
       "      <td>St Helena</td>\n",
       "      <td>royal george</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Benkuleu</td>\n",
       "      <td>walmer castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Bombay</td>\n",
       "      <td>walmer castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Madras</td>\n",
       "      <td>Motherbank</td>\n",
       "      <td>tigris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Motherbank</td>\n",
       "      <td>Madras</td>\n",
       "      <td>tigris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Madras</td>\n",
       "      <td>tigris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Point de Galle</td>\n",
       "      <td>Downs</td>\n",
       "      <td>tigris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Diamond Harbour, Bengal</td>\n",
       "      <td>earl spencer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Bombay</td>\n",
       "      <td>Downs</td>\n",
       "      <td>earl spencer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Saugor  Roads</td>\n",
       "      <td>Downs</td>\n",
       "      <td>earl spencer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Kedgeree</td>\n",
       "      <td>St Helena</td>\n",
       "      <td>aurora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Downs</td>\n",
       "      <td>Madras</td>\n",
       "      <td>essex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Bengal via St Helena</td>\n",
       "      <td>dover castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Bengal via St Helena</td>\n",
       "      <td>dover castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Point De Galle</td>\n",
       "      <td>Downs via St Helena</td>\n",
       "      <td>dover castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Motherbank</td>\n",
       "      <td>Madras</td>\n",
       "      <td>dover castle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Downs UK</td>\n",
       "      <td>Benkuleu via St Helena</td>\n",
       "      <td>york</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Motherbank</td>\n",
       "      <td>Bombay via Johanna</td>\n",
       "      <td>york</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Madras via Johanna</td>\n",
       "      <td>york</td>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VoyageFrom                 VoyageTo          ShipName  \\\n",
       "LogbookIdent                                                              \n",
       "50              Helvoetsluis                  Curacao   kenau hasselaar   \n",
       "51              Porte Praijo            Schapeneiland            havick   \n",
       "52                   Batavia                   Europa            havick   \n",
       "53                 Frankrijk         Nederlands IndiÃ«            nymphe   \n",
       "54                   Batavia               Nieuwediep   jan en cornelis   \n",
       "55                  Suriname               Nieuwediep            boreas   \n",
       "56              St Eustacius                    Texel             jason   \n",
       "57                     Texel                 Fonciaal  nassau-weilburgh   \n",
       "58                  Lissabon                 Mesurado            thetis   \n",
       "59                     Texel               West-Indie    haarlemmerhout   \n",
       "60                     Texel               West-Indie    haarlemmerhout   \n",
       "61                Vlissingen                 Suriname   st maartensdijk   \n",
       "62              St Eustatius                    Texel           amazone   \n",
       "63                Vlissingen                Tafelbaai    prins frederik   \n",
       "64                Simonsbaai               Mountsbaai    prins frederik   \n",
       "65                    Madras                  Batavia        colchester   \n",
       "66                     Downs                   Madras            alfred   \n",
       "67                 Java Head                St Helena            alfred   \n",
       "68                Simons Bay                   Madras            alfred   \n",
       "69                Simons Bay   Downs UK via St Helena    northumberland   \n",
       "70                 St Helena                   Canton    northumberland   \n",
       "71                    Bombay                   Canton    northumberland   \n",
       "72                 Dungeness                   Bombay    northumberland   \n",
       "73                     Downs                     Java   royal charlotte   \n",
       "74                     Downs        Benkulen, Sumatra   royal charlotte   \n",
       "75                    Downs                    Madras   royal charlotte   \n",
       "76                  Plymouth                 Calcutta          georgina   \n",
       "77                Motherbank                St Helena          georgina   \n",
       "78                 Table Bay                   London          georgina   \n",
       "79                      Bali                St Helena           glatton   \n",
       "80                     Downs         Sumbava (E Bali)           glatton   \n",
       "81             Fort St David                St Helena      royal george   \n",
       "82                     Downs                 Benkuleu     walmer castle   \n",
       "83                Portsmouth                   Bombay     walmer castle   \n",
       "84                    Madras               Motherbank            tigris   \n",
       "85                Motherbank                   Madras            tigris   \n",
       "86                Portsmouth                   Madras            tigris   \n",
       "87            Point de Galle                    Downs            tigris   \n",
       "88            Rio de Janeiro  Diamond Harbour, Bengal      earl spencer   \n",
       "89                    Bombay                    Downs      earl spencer   \n",
       "90             Saugor  Roads                    Downs      earl spencer   \n",
       "91                  Kedgeree                St Helena            aurora   \n",
       "92                     Downs                   Madras             essex   \n",
       "93                Portsmouth     Bengal via St Helena      dover castle   \n",
       "94                Portsmouth     Bengal via St Helena      dover castle   \n",
       "95            Point De Galle      Downs via St Helena      dover castle   \n",
       "96                Motherbank                   Madras      dover castle   \n",
       "97                  Downs UK   Benkuleu via St Helena              york   \n",
       "98                Motherbank       Bombay via Johanna              york   \n",
       "99                Portsmouth       Madras via Johanna              york   \n",
       "\n",
       "                 ShipType Nationality  Year  slave_logs  \n",
       "LogbookIdent                                             \n",
       "50                    NaN       Dutch  1802           0  \n",
       "51                  Sloep       Dutch  1796           0  \n",
       "52                 Korvet       Dutch  1810           0  \n",
       "53                 Fregat      French  1811           0  \n",
       "54            Koopvaarder       Dutch  1821           0  \n",
       "55                 Fregat       Dutch  1773           2  \n",
       "56                    NaN       Dutch  1779           1  \n",
       "57                    NaN       Dutch  1780           0  \n",
       "58                 Fregat       Dutch  1787           0  \n",
       "59                 Fregat       Dutch  1754           0  \n",
       "60                 Fregat       Dutch  1759           0  \n",
       "61                    NaN       Dutch  1763           0  \n",
       "62                 Fregat       Dutch  1769           0  \n",
       "63                    NaN       Dutch  1816           0  \n",
       "64                    NaN       Dutch  1819           0  \n",
       "65                    NaN     British  1754           0  \n",
       "66                    NaN     British  1791           0  \n",
       "67                    NaN     British  1795           0  \n",
       "68                    NaN     British  1796           0  \n",
       "69                    NaN     British  1807           0  \n",
       "70                    NaN     British  1767           0  \n",
       "71                    NaN     British  1771           0  \n",
       "72                    NaN     British  1774           0  \n",
       "73                    NaN     British  1786           0  \n",
       "74                    NaN     British  1790           0  \n",
       "75                    NaN     British  1793           0  \n",
       "76                    NaN     British  1800           0  \n",
       "77                    NaN     British  1803           0  \n",
       "78                    NaN     British  1807           0  \n",
       "79                    NaN     British  1779           0  \n",
       "80                    NaN     British  1780           0  \n",
       "81                    NaN     British  1750           0  \n",
       "82                    NaN     British  1804           0  \n",
       "83                    NaN     British  1806           0  \n",
       "84                    NaN     British  1809           0  \n",
       "85                    NaN     British  1810           0  \n",
       "86                    NaN     British  1812           0  \n",
       "87                    NaN     British  1815           0  \n",
       "88                    NaN     British  1803           0  \n",
       "89                    NaN     British  1807           0  \n",
       "90                    NaN     British  1809           0  \n",
       "91                    NaN     British  1801           0  \n",
       "92                    NaN     British  1785           0  \n",
       "93                    NaN     British  1804           0  \n",
       "94                    NaN     British  1806           0  \n",
       "95                    NaN     British  1810           0  \n",
       "96                    NaN     British  1801           0  \n",
       "97                    NaN     British  1774           0  \n",
       "98                    NaN     British  1777           0  \n",
       "99                    NaN     British  1780           0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ind += 50\n",
    "end_ind += 50\n",
    "cliwoc_data[start_ind:end_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- Mess with classifier parameters (once working)\n",
    "- test classifier for 2 validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import exploringShipLogbooks.wordCount as wc\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from exploringShipLogbooks.basic_utils import clean_data\n",
    "from exploringShipLogbooks.basic_utils import encode_data_df\n",
    "from exploringShipLogbooks.basic_utils import extract_logbook_data\n",
    "from exploringShipLogbooks.basic_utils import isolate_columns\n",
    "from exploringShipLogbooks.basic_utils import isolate_training_data\n",
    "\n",
    "from exploringShipLogbooks.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load and clean data\n",
    "### Load CLIWOC ship logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emma\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3006: DtypeWarning: Columns (5,6,7,8,11,13,18,19,23,24,25,26,28,29,30,34,35,38,43,44,46,73,77,81,82,84,85,87,88,94,96,97,98,99,111,114,116,119,120,122,124,125,127,129,131,133,135,137,140) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "# extract data from zip file\n",
    "cliwoc_data = extract_logbook_data('CLIWOC15.csv')\n",
    "#cliwoc_data = cliwoc_data.loc[50000:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoding = preprocessing.LabelEncoder().fit(cliwoc_data['LogbookIdent']).classes_\n",
    "cliwoc_data['LogbookIdent'] = preprocessing.LabelEncoder().fit_transform(cliwoc_data['LogbookIdent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find definite slave data in CLIWOC data set\n",
    "- These logs will be used to test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  464  logs that mention slaves\n"
     ]
    }
   ],
   "source": [
    "# extract logs that mention slaves\n",
    "slave_mask = wc.count_key_words(cliwoc_data, text_columns, slave_words)\n",
    "print('Found ', len(slave_mask[slave_mask==True]), ' logs that mention slaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean CLIWOC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  6517  logs that are non-slave ships\n"
     ]
    }
   ],
   "source": [
    "# find indices of ship names that are \"non-slave\" ships before dropping ship name column\n",
    "non_slave_log_locations = isolate_training_data(cliwoc_data, {'ShipName': non_slave_ships})\n",
    "print('Found ', len(non_slave_log_locations[non_slave_log_locations==True]), ' logs that are non-slave ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_data['slave_logs'] = np.zeros(len(cliwoc_data))\n",
    "slave_log_locations = cliwoc_data['LogbookIdent'].isin(list(cliwoc_data['LogbookIdent']\n",
    "                                                            [slave_mask].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cliwoc_data (unclassified) = 0\n",
    "- cliwoc_data (no slaves)    = 1\n",
    "- cliwoc_data (slaves)       = 2\n",
    "- slave_data                 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_data.loc[non_slave_log_locations,'slave_logs'] = 1\n",
    "cliwoc_data.loc[slave_log_locations,'slave_logs'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cliwoc_data = cliwoc_data.sort_values('LogbookIdent', ascending=True)\n",
    "cliwoc_data = cliwoc_data.drop_duplicates('LogbookIdent')\n",
    "cliwoc_data = cliwoc_data.set_index('LogbookIdent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VoyageFrom',\n",
       " 'VoyageTo',\n",
       " 'ShipType',\n",
       " 'Nationality',\n",
       " 'Year',\n",
       " 'slave_logs',\n",
       " 'ShipName',\n",
       " 'ShipName',\n",
       " 'ShipName']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment this if looking at ship names for manual review\n",
    "#desired_columns.append('ShipName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove undesired columns\n",
    "cliwoc_data = isolate_columns(cliwoc_data, desired_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Slave Voyages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = './exploringShipLogbooks/data/tastdb-exp-2010'\n",
    "slave_voyage_logs = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "year_ind = ~(slave_voyage_logs['yeardep'].isnull())\n",
    "slave_voyage_logs = slave_voyage_logs[year_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cliwoc_ind = (slave_voyage_logs['yeardep']>cliwoc_data['Year'].min()) & (slave_voyage_logs['yeardep']<cliwoc_data['Year'].max())\n",
    "slave_voyage_logs = slave_voyage_logs[cliwoc_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Slave voyages data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slave_voyage_desired_cols = list(slave_voyage_conversions.keys())\n",
    "slave_voyage_logs = isolate_columns(slave_voyage_logs, slave_voyage_desired_cols)\n",
    "\n",
    "slave_voyage_logs.rename(columns=slave_voyage_conversions, inplace=True)\n",
    "#slave_voyage_logs.columns = ['Nationality', 'ShipType', 'VoyageFrom', 'VoyageTo', 'Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slave_voyage_logs['slave_logs'] = 3\n",
    "slave_voyage_indices = range(len(slave_voyage_logs)) + (cliwoc_data.tail(1).index[0]+1)\n",
    "slave_voyage_logs = slave_voyage_logs.set_index(slave_voyage_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([cliwoc_data, slave_voyage_logs])\n",
    "#all_data = cliwoc_data.append(slave_voyage_logs)\n",
    "all_data = clean_data(all_data)\n",
    "\n",
    "# cleanup (my computer won't run the code without this :( )\n",
    "del cliwoc_data, slave_voyage_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of fuzzywuzzy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame( {'id':[1, 2, 3, 4, 5, 6], 'name':['dog', 'cat', 'mad cat', 'good dog', 'bad dog', 'chicken']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(name):\n",
    "    matches = df.apply(lambda row: (fuzz.partial_ratio(row['name'], name) >= 85), axis=1)\n",
    "    return [i for i, x in enumerate(matches) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 3, 4]\n",
       "1       [1, 2]\n",
       "2       [1, 2]\n",
       "3       [0, 3]\n",
       "4       [0, 4]\n",
       "5          [5]\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(lambda row: func(row['name']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try fuzzywuzzy on subset of one of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(name, column_name):\n",
    "    matches = all_data[0:10].apply(lambda row: (fuzz.partial_ratio(row[column_name], name) >= 85), axis=1)\n",
    "    return [i for i, x in enumerate(matches) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_name = 'Nationality'\n",
    "all_data[0:10].apply(lambda row: func(row[column_name], column_name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data\n",
    "- Must encode data before separating, otherwise values that do not occur in a subset will be encoded differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = encode_data_df(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove nan columns from encoding (currently there are no empty cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['no_data'] = all_data['nan'].apply(lambda x: x.any(), axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = all_data.drop('nan', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american</th>\n",
       "      <th>argentina</th>\n",
       "      <th>brazil</th>\n",
       "      <th>british</th>\n",
       "      <th>danish</th>\n",
       "      <th>denmark</th>\n",
       "      <th>dutch</th>\n",
       "      <th>france</th>\n",
       "      <th>french</th>\n",
       "      <th>great britain</th>\n",
       "      <th>...</th>\n",
       "      <th>ysla de santa cathalina</th>\n",
       "      <th>ysla de santa cathalinaysla de santa cathalina</th>\n",
       "      <th>zeeland</th>\n",
       "      <th>ziam</th>\n",
       "      <th>zierikzee</th>\n",
       "      <th>zuid afrika</th>\n",
       "      <th>zuiden</th>\n",
       "      <th>Year</th>\n",
       "      <th>slave_logs</th>\n",
       "      <th>no_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1785</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 2366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   american  argentina  brazil  british  danish  denmark  dutch  france  \\\n",
       "0         0          0       0        0       0        0      1       0   \n",
       "1         0          0       0        0       0        0      1       0   \n",
       "2         0          0       0        0       0        0      1       0   \n",
       "3         0          0       0        0       0        0      1       0   \n",
       "4         0          0       0        0       0        0      1       0   \n",
       "\n",
       "   french  great britain   ...     ysla de santa cathalina  \\\n",
       "0       0              0   ...                           0   \n",
       "1       0              0   ...                           0   \n",
       "2       0              0   ...                           0   \n",
       "3       0              0   ...                           0   \n",
       "4       0              0   ...                           0   \n",
       "\n",
       "   ysla de santa cathalinaysla de santa cathalina  zeeland  ziam  zierikzee  \\\n",
       "0                                               0        0     0          0   \n",
       "1                                               0        0     0          0   \n",
       "2                                               0        0     0          0   \n",
       "3                                               0        0     0          0   \n",
       "4                                               0        0     0          0   \n",
       "\n",
       "   zuid afrika  zuiden  Year  slave_logs  no_data  \n",
       "0            0       0  1785           0        1  \n",
       "1            0       0  1786           0        1  \n",
       "2            0       0  1786           0        1  \n",
       "3            0       0  1786           0        1  \n",
       "4            0       0  1786           0        1  \n",
       "\n",
       "[5 rows x 2366 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract training data, and create list of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unclassified_logs = all_data[all_data['slave_logs']==0]\n",
    "unclassified_logs = unclassified_logs.drop('slave_logs', axis=1)\n",
    "\n",
    "validation_set_1 = all_data[all_data['slave_logs']==2]\n",
    "validation_set_1 = validation_set_1.drop('slave_logs', axis=1)\n",
    "\n",
    "# reserve first 20% of slave_voyage_logs as validation set\n",
    "validation_set_2_indices = range(slave_voyage_indices.min(),\n",
    "                                 slave_voyage_indices.min() + round(len(slave_voyage_indices)*.2))\n",
    "validation_set_2 = all_data.iloc[validation_set_2_indices]\n",
    "validation_set_2 = validation_set_2.drop('slave_logs', axis=1)\n",
    "\n",
    "training_logs_pos = all_data.drop(validation_set_2_indices)\n",
    "training_logs_pos = training_logs_pos[training_logs_pos['slave_logs']==3]\n",
    "training_logs_pos = training_logs_pos.drop('slave_logs', axis=1)\n",
    "\n",
    "# note! This relies on cliwoc data being first in all_data\n",
    "# could make more robust later\n",
    "training_logs_neg = all_data[all_data['slave_logs']==1]\n",
    "training_logs_neg = training_logs_neg.drop('slave_logs', axis=1)\n",
    "\n",
    "# cleanup\n",
    "#del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727.8888888888889"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_logs_pos)/len(training_logs_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- left this code so we can check if there are any null values in each \n",
    "  dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def finding_null_values(df):\n",
    "    return df.isnull().sum()[df.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repeat_multiplier = round(len(training_logs_pos)/len(training_logs_neg))\n",
    "\n",
    "# create list of classes for training data (0 is for non-slave, 1 is for slave)\n",
    "# index matches training_data\n",
    "classes = np.zeros(len(training_logs_neg)).repeat(repeat_multiplier)\n",
    "#classes = np.append(classes, np.ones(len(training_logs_pos)))\n",
    "classes = np.append(classes, np.ones(len(training_logs_pos)))\n",
    "\n",
    "# join training data\n",
    "neg_rep = pd.concat([training_logs_neg]*repeat_multiplier)\n",
    "training_data = pd.concat([neg_rep, training_logs_pos], ignore_index = True)\n",
    "\n",
    "# convert to numpy array\n",
    "training_data = training_data.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fit training data to classifier\n",
    "- **note!** first column of numpy array is index! do not include in classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(alpha = 1.0, class_prior = None, fit_prior = True)\n",
    "classifier.fit(training_data[::,1::], classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classifier\n",
    "- check if slave logs from cliwoc data were classified correctly (want mostly classified as 1)\n",
    "- compare first column with slave_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_test(classifier, validation_set, expected_class):\n",
    "    \"\"\"\n",
    "    input classifer object, validation set (data frame), and expected class \n",
    "    of validation set (i.e. 1 or 0). Prints successful classification rate.\n",
    "    \"\"\"\n",
    "    validation_set = validation_set.as_matrix()\n",
    "    predictions = classifier.predict(validation_set[::,1::])\n",
    "    \n",
    "    counts = collections.Counter(predictions)\n",
    "    percent_correct = (counts[expected_class]/(len(predictions))* 100)\n",
    "                       \n",
    "    print('Validation set was classified as', expected_class,\n",
    "          round(percent_correct,2), '% of the time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_class(classifier, data_subset):\n",
    "    \"\"\"\n",
    "    Predict class of data, and append predictions to data frame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # drop old predictions before reclassifying (if they exist)\n",
    "        data_subset = data_subset.drop('predictions', axis = 1)\n",
    "        data_to_classify = data_subset.copy()\n",
    "    except:\n",
    "        data_to_classify = data_subset.copy()\n",
    "        pass\n",
    "    \n",
    "    # convert to numpy and classify\n",
    "    data_matrix = data_to_classify.as_matrix()\n",
    "    predictions = classifier.predict(data_matrix[::,1::])\n",
    "    \n",
    "    # append predictions to dataframe\n",
    "    data_to_classify['predictions'] = predictions\n",
    "    \n",
    "    # print statstics\n",
    "    counts = collections.Counter(predictions)\n",
    "    \n",
    "    for key in counts:\n",
    "        percent = (counts[key]/(len(predictions))* 100)\n",
    "        print(round(percent, 2), 'of data was classified as ', key)\n",
    "\n",
    "    return data_to_classify\n",
    "    \n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing validation data from slave logs data set\n",
      "Validation set was classified as 1 99.95 % of the time\n",
      "Testing validation data from cliwoc data set:\n",
      "Validation set was classified as 1 0.0 % of the time\n"
     ]
    }
   ],
   "source": [
    "print('Testing validation data from slave logs data set')\n",
    "validation_test(classifier, validation_set_2, 1)\n",
    "\n",
    "print('Testing validation data from cliwoc data set:')\n",
    "validation_test(classifier, validation_set_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.74 of data was classified as  0.0\n",
      "0.26 of data was classified as  1.0\n"
     ]
    }
   ],
   "source": [
    "unclassified_logs = append_predictions(classifier, unclassified_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
